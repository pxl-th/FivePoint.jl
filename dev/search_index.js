var documenterSearchIndex = {"docs":
[{"location":"triangulation/#Triangulation","page":"Triangulation","title":"Triangulation","text":"","category":"section"},{"location":"triangulation/","page":"Triangulation","title":"Triangulation","text":"triangulate","category":"page"},{"location":"triangulation/#RecoverPose.triangulate","page":"Triangulation","title":"RecoverPose.triangulate","text":"triangulate(p1, p2, P1, P2)\n\nTriangulate point given its two projection coordinates and projection matrices.\n\nArguments:\n\np1: Pixel coordinates of a point in (x, y) format in the first view.\np2: Pixel coordinates of a point in (x, y) format in the second view.\nP1: 3x4 or 4x4 projection matrix K * P for the first view.\nP2: 3x4 or 4x4 projection matrix K * P for the second view.\n\nReturns:\n\nTriangulated point in (x, y, z, w) format. To get actual coordinates, divide by w.\n\n\n\n\n\n","category":"function"},{"location":"five-point/#FivePoint-algorithm","page":"Five Point","title":"FivePoint algorithm","text":"","category":"section"},{"location":"five-point/","page":"Five Point","title":"Five Point","text":"Used for computing Essential matrix and pose matrix from it.","category":"page"},{"location":"five-point/","page":"Five Point","title":"Five Point","text":"five_point\nfive_point_ransac\nessential_ransac","category":"page"},{"location":"five-point/#RecoverPose.five_point","page":"Five Point","title":"RecoverPose.five_point","text":"five_point(points1, points2, K1, K2; max_repr_error = 1.0)\n\nCompute Essential matrix and recover pose from it for a given set of points. This function accepts five points, if you have more of them, consider using five_point_ransac version.\n\nArguments:\n\npoints1:   Pixel coordinates of the matched points in (x, y) format   in the first image.\npoints2:   Pixel coordinates of the matched points in (x, y) format   in the second image.\nK1: Intrinsic matrix for the first set of points.\nK2: Intrinsic matrix for the second set of points.\nmax_repr_error: Maximum allowed reprojection error for a point to be   considered as inlier. Default is 1.0.\n\nReturns:\n\nn_inliers, (E, P, inliers, repr_error):\n\nnumber of inliers\ntuple: essential matrix, pose matrix, boolean vector of inliers, error value.\n\nnote: Note\nPose matrix transforms points from the first camera to the second camera.\n\n\n\n\n\n","category":"function"},{"location":"five-point/#RecoverPose.five_point_ransac","page":"Five Point","title":"RecoverPose.five_point_ransac","text":"five_point_ransac(\n    points1, points2, K1, K2; max_repr_error = 1.0, ransac_kwargs...)\n\nCompute Essential matrix and recover pose from it using RANSAC scheme.\n\nArguments:\n\npoints1:   Pixel coordinates of the matched points in (x, y) format   in the first image.\npoints2:   Pixel coordinates of the matched points in (x, y) format   in the second image.\nK1: Intrinsic matrix for the first set of points.\nK2: Intrinsic matrix for the second set of points.\nmax_repr_error: Maximum allowed reprojection error for a point to be   considered as inlier. Default is 1.0.\nransac_kwargs...: Keyword arguments passed to ransac.\n\nReturns:\n\nn_inliers, (E, P, inliers, repr_error):\n\nnumber of inliers\ntuple: essential matrix, pose matrix, boolean vector of inliers, error value.\n\nnote: Note\nPose matrix transforms points from the first camera to the second camera.\n\n\n\n\n\n","category":"function"},{"location":"five-point/#RecoverPose.essential_ransac","page":"Five Point","title":"RecoverPose.essential_ransac","text":"essential_ransac(pixels1, pixels2, K1, K2; threshold = 1.0, ransac_kwargs...)\n\nCompute Essential matrix using the RANASC scheme.\n\nArguments:\n\npd1:   Pixel coordinates predivided by K^-1 of the matched points   in (x, y) format in the first image.\npd2:   Pixel coordinates predivided by K^-1 of the matched points   in (x, y) format in the second image.\nfocal_sum: fx + fy.\nthreshold: Maximum error for the epipolar constraint. Default is 1.0.\nransac_kwargs...: Keyword arguments passed to ransac.\n\nReturns:\n\nn_inliers, (E, P, inliers, repr_error):\n\nnumber of inliers\ntuple: essential matrix, boolean vector of inliers, error value.\n\n\n\n\n\n","category":"function"},{"location":"p3p/#Perspective-3-Point","page":"P3P","title":"Perspective-3-Point","text":"","category":"section"},{"location":"p3p/","page":"P3P","title":"P3P","text":"p3p\np3p_select_model\np3p_ransac\npre_divide_normalize","category":"page"},{"location":"p3p/#RecoverPose.p3p","page":"P3P","title":"RecoverPose.p3p","text":"p3p(points, pdn_pixels::AbstractVector{SVector{3, T}}, K)\n\nRecover pose using P3P algorithm.\n\nArguments:\n\npoints: Vector of 3D points in(x, y, z)` format.\npdn_pixels::AbstractVector{SVector{3, Float64}}:   Corresponding projections of points onto image plane,   predivided by K intrinsics and normalized.   E.g.: Ki = inv(K); p = Ki [x, y, 1]; p /= norm(p).\nK::SMatrix{3, 3, Float64}: Camera intrinsics.\n\nReturns:\n\nVector{SMatrix{3, 4, Float64}} vector of up to 4 possible solutions. Each element is a projection matrix P = K * [R|t]. To get pure transformation matrix, multiply P by inv(K).\n\nReferences:\n\nLink: https://cmp.felk.cvut.cz/~pajdla/gvg/GVG-2016-Lecture.pdf\nchapter: 7.3 Calibrated camera pose computation.\npages: 51-59\n\n\n\n\n\n","category":"function"},{"location":"p3p/#RecoverPose.p3p_select_model","page":"P3P","title":"RecoverPose.p3p_select_model","text":"p3p_select_model(models, points, pixels; threshold = 1.0)\n\nSelect best pose from models.\n\nArguments:\n\nmodels: Projection matrices from which to select best one.\npoints: 3D points in (x, y, z)\npixels: Corresponding projections onto image plane in (x, y) format.\nthreshold: Maximum distance in pixels between projected point   and its target pixel, for the point to be considered inlier.   Default value is 1.0.\n\nReturns:\n\nn_inliers, (projection, inliers, error).\n\nn_inliers: Number of inliers for the projection.\nprojection: K * P projection matrix that projects points   onto image plane.\ninliers: Boolean vector indicating which point is inlier.\nerror: Average reprojection error for the pose.\n\n\n\n\n\n","category":"function"},{"location":"p3p/#RecoverPose.p3p_ransac","page":"P3P","title":"RecoverPose.p3p_ransac","text":"p3p_ransac(points, pixels, pdn_pixels, K; threshold = 1.0, ransac_kwargs...)\n\nRecover pose K*[R|t] using P3P Ransac algorithm.\n\nArguments:\n\npoints: 3D points in (x, y, z)\npixels: Corresponding projections onto image plane in (x, y) format.\npdn_pixels: Corresponding projections onto image plane,   predivided by K intrinsics and normalized.   E.g.: Ki = inv(K); p = Ki [x, y, 1]; p /= norm(p).\nK: Camera intrinsics.\nthreshold: Maximum distance in pixels between projected point   and its target pixel, for the point to be considered inlier.   Default value is 1.0.\nransac_kwargs...: Keyword arguments passed to ransac.\n\nReturns:\n\nn_inliers, (projection, inliers, error).\n\nn_inliers: Number of inliers for the projection.\nprojection: K * P projection matrix that projects points   onto image plane.\ninliers: Boolean vector indicating which point is inlier.\nerror: Average reprojection error for the pose.\n\nReferences:\n\nLink: https://cmp.felk.cvut.cz/~pajdla/gvg/GVG-2016-Lecture.pdf\nchapter: 7.3 Calibrated camera pose computation.\npages: 51-59\n\n\n\n\n\np3p_ransac(points, pixels, K; threshold = 1.0, ransac_kwargs...)\n\nRecover pose K*[R|t] using P3P Ransac algorithm.\n\nArguments:\n\npoints: 3D points in (x, y, z)\npixels: Corresponding projections onto image plane in (x, y) format.   These values, WILL be predivided and normalized by the intrinsic matrix.   E.g.: Ki = inv(K); p = Ki [x, y, 1]; p /= norm(p).\nK: Camera intrinsics.\nthreshold::Real:   Maximum distance in pixels between projected point and its target pixel,   for the point to be considered inlier. Default value is 1.0.\nransac_kwargs...: Keyword arguments passed to ransac.\n\nReturns:\n\nVector{SMatrix{3, 4, Float64}} vector of up to 4 possible solutions. Each element is a projection matrix P = K * [R|t]. To get pure transformation matrix, multiply P by inv(K).\n\nReferences:\n\nLink: https://cmp.felk.cvut.cz/~pajdla/gvg/GVG-2016-Lecture.pdf\nchapter: 7.3 Calibrated camera pose computation.\npages: 51-59\n\n\n\n\n\n","category":"function"},{"location":"p3p/#RecoverPose.pre_divide_normalize","page":"P3P","title":"RecoverPose.pre_divide_normalize","text":"pre_divide_normalize(pixels, K)\n\nDivide pixels by K intrinsic matrix and normalize them. pixels in (x, y) format.\n\n\n\n\n\n","category":"function"},{"location":"#RecoverPose.jl","page":"Home","title":"RecoverPose.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Different methods for pose recovery.","category":"page"},{"location":"ransac/#RANSAC","page":"RANSAC","title":"RANSAC","text":"","category":"section"},{"location":"ransac/","page":"RANSAC","title":"RANSAC","text":"ransac","category":"page"},{"location":"ransac/#RecoverPose.ransac","page":"RANSAC","title":"RecoverPose.ransac","text":"RANSAC algorithm used when there are more points than algorithm requires.\n\nArguments:\n\nsample_selector: Function that given set of ids of the size n_samples,   returns input for the kernel method.\nkernel: Function that calculates candidates from the sampled data.\nrank: Function that evaluates candidates, computed by kernel.   It should return n_inliers, model, where model can be of any type.   And is not used by the ransac itself. It only uses n_inliers to select   which model is better.\nn_points: Total number of points in the data.\nn_samples: Number of points, that kernel function accepts.   E.g. five_point_ransac sets this value to 5.\niterations: Maximum number of iterations to attempt. Default is 100.\nconfidence: Confidence in [0, 1] range. The higher the value, the more   certain algorithm is that the picked model does not contain outliers.   Number of iterations performed by RANSAC depends on this value as well.\n\nReturns:\n\nNumber of inliers and the selected model in the format returned by kernel.\n\n\n\n\n\n","category":"function"}]
}
